{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion for Space Exploration RAG\n",
    "\n",
    "This notebook demonstrates how to load data from Wikipedia, split it into chunks, and index it into a local VectorDB (Chroma) for our RAG application.\n",
    "Submitted by: Amina O. & Ossama Z. & Smia I.\n",
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "# Define the directory for persistent storage\n",
    "PERSIST_DIRECTORY = \"./chroma_db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data from Wikipedia\n",
    "We will load articles related to Space Exploration to build our knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"Space exploration\", \"NASA\", \"SpaceX\", \"Mars exploration\", \"International Space Station\"]\n",
    "documents = []\n",
    "\n",
    "print(\"Loading documents from Wikipedia...\")\n",
    "for topic in topics:\n",
    "    try:\n",
    "        loader = WikipediaLoader(query=topic, load_max_docs=1)\n",
    "        docs = loader.load()\n",
    "        documents.extend(docs)\n",
    "        print(f\"Loaded: {topic}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {topic}: {e}\")\n",
    "\n",
    "print(f\"Total documents loaded: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Split Text into Chunks\n",
    "We need to split the long articles into smaller chunks for flexible retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "splits = text_splitter.split_documents(documents)\n",
    "print(f\"Created {len(splits)} chunks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embed and Store in ChromaDB\n",
    "We will use a local HuggingFace embedding model (`all-MiniLM-L6-v2`) which is lightweight and efficient.\n",
    "The data will be saved locally to `./chroma_db`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing Embedding Model...\")\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "print(\"Indexing data into ChromaDB... (This might take a minute)\")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=PERSIST_DIRECTORY\n",
    ")\n",
    "\n",
    "print(\"Done! Data indexed and saved to ./chroma_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test Retrieval\n",
    "Let's verify that we can retrieve relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who founded SpaceX?\"\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "results = retriever.invoke(query)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Top Result:\")\n",
    "print(results[0].page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
